## Introduction
The Weight Lifting Exercises (WLE) data set [1] are sensor recorded data of six persons performing one exercise (Unilateral Dumbbell Biceps Curl) in five different fashions: class A is the correct manner while classes B-E are different types of incorrect manners.  We will build a model to predict the class of exercise from sensor data and estimate the out-of-sample error rate of this model.

## R Libraries
```{r}
library(dplyr)
library(randomForest)
library(caret)
```

## Data Input
```{r, cache=TRUE}
url.train <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'
url.test <- 'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'
df.train <- read.csv(url.train)
df.test <- read.csv(url.test)
```

## Data Preprocessing
First we check the ratio of NAs in each column in the training set and test set.  

```{r}
table(colMeans(is.na(df.train)))
table(colMeans(is.na(df.test)))
```
There are 67 columns in training set and 100 columns in test set with very high ratios of NAs.  We further extract the names of test columns and check the difference.

```{r}
cols.na.train <- names(df.train)[colMeans(is.na(df.train)) > 0.9]
cols.na.test <-  names(df.test)[colMeans(is.na(df.test)) > 0.9]
setdiff(cols.na.train, cols.na.test)
setdiff(cols.na.test, cols.na.train)
```
The set "cols.na.test"" is a larger set and contains the set "cols.na.train".  Thus we remove columns in "cols.na.test".
```{r}
df.train2 <- df.train[,setdiff(names(df.train),cols.na.test)]
df.test2 <- df.test[,setdiff(names(df.test),cols.na.test)]
dim(df.train2)
dim(df.test2)
names(df.train2)
```
The first few features include user and time related information.  Based on the experiment, a user did one class of exercise for a period of time, then he moved on to the next class, so on and so forth.  The user and time related information could have strong predictive power but won't be generalized to new data recorded by other users or in the future.  These features should not be used in model training and thus are removed.
```{r}
names(df.train2)[1:7]
df.train2 <- select(df.train2, -(X:num_window))
df.test2 <- select(df.test2, -(X:num_window))
dim(df.train2)
dim(df.test2)
```
## Data Splitting
To evaluate out-of-sample performance, we reserve 40% of data for validation.
```{r}
seed = 123
set.seed(seed)
trainIndex <- createDataPartition(df.train2$classe, p = .6,
                                  list = FALSE)
df.train.split <- df.train2[trainIndex,]
df.validate.split <- df.train2[-trainIndex,]
```
## Model for Machine Learning
The random forest model is used for machine learning.  This model has a built-in validation mechanism called out-of-bag (oob) error estimation [2].  Thus we will get two estimates of the out-of-sample error rate.

```{r, cache=TRUE}
fit.rf <- randomForest(classe~., df.train.split)
fit.rf
```

## Validation
Then we apply the model to the validation set and compare the prediction output to the reference classes.
```{r}
pred <- predict(fit.rf, newdata=df.validate.split)
conf <- confusionMatrix(pred, df.validate.split$classe)
conf
```

## Out-of-sample Error Rate
Now we have two error rate estimates, one from the validation and the other from OOB of random forest model.  These two numbers look quite consistent.
```{r}
errorRate.validate <-  1 - conf$overall[["Accuracy"]]
errorRate.oob <- tail(fit.rf$err.rate,1)[,"OOB"]
errorRate.validate
errorRate.oob
```


## Reference
1. Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.
Read more: http://groupware.les.inf.puc-rio.br/har#wle_paper_section#ixzz3ALjBH6NX

2. http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#ooberr
